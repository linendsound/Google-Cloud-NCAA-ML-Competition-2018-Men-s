{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier as Ada\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(year = 2018):\n",
    "    train_data = pd.read_csv('../ouput/train_'+str(year)+'.csv')\n",
    "\n",
    "    train_data['WTseed']= train_data['WTseed'].fillna(18)####\n",
    "    train_data['LTseed']= train_data['LTseed'].fillna(18)####\n",
    "\n",
    "    train_data['ID'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    train_data['IDTeams'] = train_data.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    train_data['Team1'] = train_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "    train_data['Team2'] = train_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "    train_data['IDTeam1'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "    train_data['IDTeam2'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "    train_data['Pred'] = train_data.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "    train_data['ScoreDiff'] = train_data['WScore']-train_data['LScore']\n",
    "    train_data['ScoreDiff'] = train_data.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "    train_data['Team1Score'] = train_data.apply(lambda r: r['WScore'] if r['Pred'] == 1. else r['LScore'],axis=1)\n",
    "    train_data['Team2Score'] = train_data.apply(lambda r: r['WScore'] if r['Pred'] == 0. else r['LScore'],axis=1)\n",
    "    train_data['Team1Seed'] = train_data.apply(lambda r: r['WTseed']if r['Pred'] == 1. else r['LTseed'],axis=1)\n",
    "    train_data['Team2Seed'] = train_data.apply(lambda r: r['WTseed']if r['Pred'] == 0. else r['LTseed'],axis=1)\n",
    "    train_data['SeedDiff'] = train_data.apply(lambda r: r['Team1Seed']-r['Team2Seed'],axis = 1)\n",
    "    train_data['Team1ScoreRatio'] = train_data['Team1Score']/(train_data['Team1Score']+train_data['Team2Score'])\n",
    "    train_data['Team2ScoreRatio'] = train_data['Team2Score']/(train_data['Team1Score']+train_data['Team2Score'])\n",
    "    train_data['Team1Loc'] = train_data.apply(lambda r: r['WLoc'] if r['Pred'] == 1 else None,axis=1)\n",
    "    train_data['Team2Loc'] = train_data.apply(lambda r: r['WLoc'] if r['Pred'] == 0 else None,axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[1]=='N' else r[0],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[0]=='N' else r[1],axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[1]=='H' else r[0],axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[1]=='A' else r[0],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[0]=='H' else r[1],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[0]=='A' else r[1],axis=1)\n",
    "    \n",
    "    train_data = train_data.drop(['index','DayNum','WScore','LScore','WTseed','LTseed','WTeamID','LTeamID'],axis=1)\n",
    "\n",
    "\n",
    "    team1d_score_spread = train_data.groupby(['Season', 'Team1'])[['ScoreDiff', 'Team1Score','Team1ScoreRatio']].mean().reset_index()\\\n",
    "    .set_index('Season').rename(columns = {'ScoreDiff' : 'ScoreDiff1','Team1ScoreRatio':'Team1ScoreRatio_avg','Team1Score':'Team1Score_avg'})\n",
    "    team2d_score_spread = train_data.groupby(['Season', 'Team2'])[['ScoreDiff', 'Team2Score','Team2ScoreRatio']].mean().reset_index()\\\n",
    "    .set_index('Season').rename(columns = {'ScoreDiff' : 'ScoreDiff2','Team2ScoreRatio':'Team2ScoreRatio_avg','Team2Score':'Team2Score_avg'})\n",
    "    score_spread = team1d_score_spread.join(team2d_score_spread).reset_index()\n",
    "\n",
    "    X_train = pd.merge(train_data,score_spread,on=['Team1','Team2','Season'])\n",
    "\n",
    "    y_train = X_train['Pred']\n",
    "    X_train = X_train.drop(['WLoc','NumOT','Pred','Team1Score','Team2Score','Team1ScoreRatio','Team2ScoreRatio','ScoreDiff'],axis=1)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process1(df):\n",
    "    df =df.drop(['Unnamed: 0',\"Season\",\"ID\",\"IDTeams\",\"Team1\",\"Team2\",\"IDTeam1\",\"IDTeam2\"],axis=1)\n",
    "    Lsea=pd.get_dummies(df[\"Lsea\"],prefix=\"Lsea\")\n",
    "    Wsea=pd.get_dummies(df[\"Wsea\"],prefix=\"Wsea\")\n",
    "    df=pd.concat([df,Lsea,Wsea],axis=1)\n",
    "    df[\"Team1Loc\"]=df[\"Team1Loc\"].astype(\"category\")\n",
    "    df[\"Team2Loc\"]=df[\"Team2Loc\"].astype(\"category\")\n",
    "    df.Team1Loc=df.Team1Loc.cat.rename_categories([0,2,1])\n",
    "    df.Team2Loc=df.Team2Loc.cat.rename_categories([0,2,1])\n",
    "    df=df.drop([\"Lsea\",\"Wsea\"],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_process1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,val\n",
    "x_tr, x_val ,y_tr,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridcv(estimator,X,y,params):\n",
    "    \n",
    "    gridsearch = GridSearchCV(estimator=estimator,\n",
    "                              param_grid=params,\n",
    "                              scoring=\"roc_auc\",\n",
    "                              n_jobs=2,\n",
    "                              iid=False,\n",
    "                              cv=5)\n",
    "    \n",
    "    gridsearch.fit(X,y)\n",
    "    \n",
    "    return gridsearch.grid_scores_, gridsearch.best_params_, gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "#logistic regression\n",
    "logreg = LogisticRegression(penalty='l2',\n",
    "                            random_state=seed, \n",
    "                            solver='sag',\n",
    "                            max_iter=160,\n",
    "                            )\n",
    "#SVM\n",
    "svm_cf =SVC(C=1.0, \n",
    "            kernel='rbf', \n",
    "            degree=3, \n",
    "            gamma='auto', \n",
    "            coef0=0.0, \n",
    "            shrinking=True, \n",
    "            probability=False, \n",
    "            tol=0.001, \n",
    "            cache_size=200, \n",
    "            class_weight=None, verbose=False, \n",
    "            max_iter=-1, \n",
    "            decision_function_shape='ovr', \n",
    "            random_state=seed)\n",
    "\n",
    "#Adaboost\n",
    "ada_cf = Ada(base_estimator=None, \n",
    "             n_estimators=50, \n",
    "             learning_rate=1.0, \n",
    "             algorithm='SAMME.R', \n",
    "             random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters tuning\n",
    "params ={\n",
    "}\n",
    "gridcv(svm_cf,x_tr,y_tr,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
