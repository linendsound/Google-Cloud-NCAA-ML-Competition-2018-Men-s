{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "import csv\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(year = 2017):\n",
    "    train_data = pd.read_csv('../ouput/train_'+str(year)+'.csv')\n",
    "\n",
    "    train_data['WTseed']= train_data['WTseed'].fillna(18)####\n",
    "    train_data['LTseed']= train_data['LTseed'].fillna(18)####\n",
    "\n",
    "    train_data['ID'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    train_data['IDTeams'] = train_data.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    train_data['Team1'] = train_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "    train_data['Team2'] = train_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "    train_data['IDTeam1'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "    train_data['IDTeam2'] = train_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "    train_data['Pred'] = train_data.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "    train_data['ScoreDiff'] = train_data['WScore']-train_data['LScore']\n",
    "    train_data['ScoreDiff'] = train_data.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "    train_data['Team1Score'] = train_data.apply(lambda r: r['WScore'] if r['Pred'] == 1. else r['LScore'],axis=1)\n",
    "    train_data['Team2Score'] = train_data.apply(lambda r: r['WScore'] if r['Pred'] == 0. else r['LScore'],axis=1)\n",
    "    train_data['Team1Seed'] = train_data.apply(lambda r: r['WTseed']if r['Pred'] == 1. else r['LTseed'],axis=1)\n",
    "    train_data['Team2Seed'] = train_data.apply(lambda r: r['WTseed']if r['Pred'] == 0. else r['LTseed'],axis=1)\n",
    "    train_data['SeedDiff'] = train_data.apply(lambda r: r['Team1Seed']-r['Team2Seed'],axis = 1)\n",
    "    train_data['Team1ScoreRatio'] = train_data['Team1Score']/(train_data['Team1Score']+train_data['Team2Score'])\n",
    "    train_data['Team2ScoreRatio'] = train_data['Team2Score']/(train_data['Team1Score']+train_data['Team2Score'])\n",
    "    train_data['Team1Loc'] = train_data.apply(lambda r: r['WLoc'] if r['Pred'] == 1 else None,axis=1)\n",
    "    train_data['Team2Loc'] = train_data.apply(lambda r: r['WLoc'] if r['Pred'] == 0 else None,axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[1]=='N' else r[0],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[0]=='N' else r[1],axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[1]=='H' else r[0],axis=1)\n",
    "    train_data['Team1Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[1]=='A' else r[0],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[0]=='H' else r[1],axis=1)\n",
    "    train_data['Team2Loc'] = train_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[0]=='A' else r[1],axis=1)\n",
    "    \n",
    "    train_data = train_data.drop(['index','DayNum','WScore','LScore','WTseed','LTseed','WTeamID','LTeamID'],axis=1)\n",
    "\n",
    "\n",
    "    team1d_score_spread = train_data.groupby(['Season', 'Team1'])[['ScoreDiff', 'Team1Score','Team1ScoreRatio']].mean().reset_index()\\\n",
    "    .set_index('Season').rename(columns = {'ScoreDiff' : 'ScoreDiff1','Team1ScoreRatio':'Team1ScoreRatio_avg','Team1Score':'Team1Score_avg'})\n",
    "    team2d_score_spread = train_data.groupby(['Season', 'Team2'])[['ScoreDiff', 'Team2Score','Team2ScoreRatio']].mean().reset_index()\\\n",
    "    .set_index('Season').rename(columns = {'ScoreDiff' : 'ScoreDiff2','Team2ScoreRatio':'Team2ScoreRatio_avg','Team2Score':'Team2Score_avg'})\n",
    "    score_spread = team1d_score_spread.join(team2d_score_spread).reset_index()\n",
    "\n",
    "    X_train = pd.merge(train_data,score_spread,on=['Team1','Team2','Season'])\n",
    "\n",
    "    y_train = X_train['Pred']\n",
    "    X_train = X_train.drop(['WLoc','NumOT','Pred','Team1Score','Team2Score','Team1ScoreRatio','Team2ScoreRatio','ScoreDiff'],axis=1)\n",
    "    \n",
    "    test_data = pd.read_csv('../ouput/test_'+str(year)+'.csv')\n",
    "    test_data = test_data.drop(['index','DayNum','NumOT'],axis=1)\n",
    "    test_data['WTseed']= test_data['WTseed'].fillna(18)####\n",
    "    test_data['LTseed']= test_data['LTseed'].fillna(18)####\n",
    "    test_data['ID'] = test_data.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    test_data['IDTeams'] = test_data.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "    test_data['Team1'] = test_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "    test_data['Team2'] = test_data.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "    test_data['IDTeam1'] = test_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "    test_data['IDTeam2'] = test_data.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "    test_data['Pred'] = test_data.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "    test_data['Team1Seed'] = test_data.apply(lambda r: r['WTseed']if r['Pred'] == 1. else r['LTseed'],axis=1)\n",
    "    test_data['Team2Seed'] = test_data.apply(lambda r: r['WTseed']if r['Pred'] == 0. else r['LTseed'],axis=1)\n",
    "    test_data['SeedDiff'] = test_data.apply(lambda r: r['Team1Seed']-r['Team2Seed'],axis = 1)\n",
    "    test_data = test_data.drop(['WScore','LScore','WTseed','LTseed','WTeamID','LTeamID'],axis=1)\n",
    "    test_data['Team1Loc'] = test_data.apply(lambda r: r['WLoc'] if r['Pred'] == 1 else None,axis=1)\n",
    "    test_data['Team2Loc'] = test_data.apply(lambda r: r['WLoc'] if r['Pred'] == 0 else None,axis=1)\n",
    "    test_data['Team1Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[1]=='N' else r[0],axis=1)\n",
    "    test_data['Team2Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'N' if r[0]=='N' else r[1],axis=1)\n",
    "    test_data['Team1Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[1]=='H' else r[0],axis=1)\n",
    "    test_data['Team1Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[1]=='A' else r[0],axis=1)\n",
    "    test_data['Team2Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'A' if r[0]=='H' else r[1],axis=1)\n",
    "    test_data['Team2Loc'] = test_data[['Team1Loc','Team2Loc']].apply(lambda r: 'H' if r[0]=='A' else r[1],axis=1)\n",
    "    X_test = pd.merge(test_data,score_spread,on=['Team1','Team2','Season'])\n",
    "    y_test = X_test['Pred']\n",
    "    X_test = X_test.drop(['Pred',\"WLoc\"],axis=1)\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lsea</th>\n",
       "      <th>Season</th>\n",
       "      <th>Wsea</th>\n",
       "      <th>ID</th>\n",
       "      <th>IDTeams</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>IDTeam1</th>\n",
       "      <th>IDTeam2</th>\n",
       "      <th>...</th>\n",
       "      <th>Team2Seed</th>\n",
       "      <th>SeedDiff</th>\n",
       "      <th>Team1Loc</th>\n",
       "      <th>Team2Loc</th>\n",
       "      <th>ScoreDiff1</th>\n",
       "      <th>Team1Score_avg</th>\n",
       "      <th>Team1ScoreRatio_avg</th>\n",
       "      <th>ScoreDiff2</th>\n",
       "      <th>Team2Score_avg</th>\n",
       "      <th>Team2ScoreRatio_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017_1104_1157</td>\n",
       "      <td>1104_1157</td>\n",
       "      <td>1104</td>\n",
       "      <td>1157</td>\n",
       "      <td>2017_1104</td>\n",
       "      <td>2017_1157</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>4.151515</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>0.516269</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>0.476035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017_1107_1336</td>\n",
       "      <td>1107_1336</td>\n",
       "      <td>1107</td>\n",
       "      <td>1336</td>\n",
       "      <td>2017_1107</td>\n",
       "      <td>2017_1336</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>4.787879</td>\n",
       "      <td>71.030303</td>\n",
       "      <td>0.515335</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.497694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2017</td>\n",
       "      <td>X</td>\n",
       "      <td>2017_1112_1277</td>\n",
       "      <td>1112_1277</td>\n",
       "      <td>1112</td>\n",
       "      <td>1277</td>\n",
       "      <td>2017_1112</td>\n",
       "      <td>2017_1277</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10.823529</td>\n",
       "      <td>76.264706</td>\n",
       "      <td>0.538339</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>65.909091</td>\n",
       "      <td>0.476381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017_1113_1340</td>\n",
       "      <td>1113_1340</td>\n",
       "      <td>1113</td>\n",
       "      <td>1340</td>\n",
       "      <td>2017_1113</td>\n",
       "      <td>2017_1340</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.354839</td>\n",
       "      <td>79.290323</td>\n",
       "      <td>0.490979</td>\n",
       "      <td>1.913043</td>\n",
       "      <td>80.913043</td>\n",
       "      <td>0.493927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>Z</td>\n",
       "      <td>2017_1116_1236</td>\n",
       "      <td>1116_1236</td>\n",
       "      <td>1116</td>\n",
       "      <td>1236</td>\n",
       "      <td>2017_1116</td>\n",
       "      <td>2017_1236</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>5.393939</td>\n",
       "      <td>79.575758</td>\n",
       "      <td>0.517562</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>83.125000</td>\n",
       "      <td>0.509532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Lsea  Season Wsea              ID    IDTeams  Team1  Team2  \\\n",
       "0           0  NaN    2017  NaN  2017_1104_1157  1104_1157   1104   1157   \n",
       "1           1  NaN    2017  NaN  2017_1107_1336  1107_1336   1107   1336   \n",
       "2           2    Y    2017    X  2017_1112_1277  1112_1277   1112   1277   \n",
       "3           3  NaN    2017  NaN  2017_1113_1340  1113_1340   1113   1340   \n",
       "4           4  NaN    2017    Z  2017_1116_1236  1116_1236   1116   1236   \n",
       "\n",
       "     IDTeam1    IDTeam2         ...           Team2Seed  SeedDiff  Team1Loc  \\\n",
       "0  2017_1104  2017_1157         ...                18.0       0.0         H   \n",
       "1  2017_1107  2017_1336         ...                18.0       0.0         A   \n",
       "2  2017_1112  2017_1277         ...                 9.0      -7.0         N   \n",
       "3  2017_1113  2017_1340         ...                18.0       0.0         H   \n",
       "4  2017_1116  2017_1236         ...                18.0     -10.0         H   \n",
       "\n",
       "  Team2Loc ScoreDiff1  Team1Score_avg  Team1ScoreRatio_avg  ScoreDiff2  \\\n",
       "0        A   4.151515       68.666667             0.516269    7.100000   \n",
       "1        H   4.787879       71.030303             0.515335    0.720000   \n",
       "2        N  10.823529       76.264706             0.538339    6.272727   \n",
       "3        A  -2.354839       79.290323             0.490979    1.913043   \n",
       "4        A   5.393939       79.575758             0.517562   -3.500000   \n",
       "\n",
       "   Team2Score_avg  Team2ScoreRatio_avg  \n",
       "0       68.500000             0.476035  \n",
       "1       73.000000             0.497694  \n",
       "2       65.909091             0.476381  \n",
       "3       80.913043             0.493927  \n",
       "4       83.125000             0.509532  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process1(df):\n",
    "    df =df.drop(['Unnamed: 0',\"Season\",\"ID\",\"IDTeams\",\"Team1\",\"Team2\",\"IDTeam1\",\"IDTeam2\"],axis=1)\n",
    "    Lsea=pd.get_dummies(df[\"Lsea\"],prefix=\"Lsea\")\n",
    "    Wsea=pd.get_dummies(df[\"Wsea\"],prefix=\"Wsea\")\n",
    "    df=pd.concat([df,Lsea,Wsea],axis=1)\n",
    "    df[\"Team1Loc\"]=df[\"Team1Loc\"].astype(\"category\")\n",
    "    df[\"Team2Loc\"]=df[\"Team2Loc\"].astype(\"category\")\n",
    "    df.Team1Loc=df.Team1Loc.cat.rename_categories([0,2,1])\n",
    "    df.Team2Loc=df.Team2Loc.cat.rename_categories([0,2,1])\n",
    "    df=df.drop([\"Lsea\",\"Wsea\"],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process2(df):\n",
    "    df =df.drop(['Unnamed: 0',\"Season\",\"ID\",\"IDTeams\",\"Team1\",\"Team2\",\"IDTeam1\",\"IDTeam2\"],axis=1)\n",
    "    Lsea=pd.get_dummies(df[\"Lsea\"],prefix=\"Lsea\")\n",
    "    Wsea=pd.get_dummies(df[\"Wsea\"],prefix=\"Wsea\")\n",
    "    df=pd.concat([df,Lsea,Wsea],axis=1)\n",
    "    df[\"Team1Loc\"]=df[\"Team1Loc\"].astype(\"category\")\n",
    "    df[\"Team2Loc\"]=df[\"Team2Loc\"].astype(\"category\")\n",
    "    df.Team1Loc=df.Team1Loc.cat.rename_categories([1])\n",
    "    df.Team2Loc=df.Team2Loc.cat.rename_categories([1])\n",
    "    df=df.drop([\"Lsea\",\"Wsea\"],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y,y_hat):\n",
    "    scale = len(y)\n",
    "    loss = -np.sum(y*np.log(y_hat[:,1])+(1-y)*np.log(1-y_hat[:,0]))/scale\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_process1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_process2(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1Seed</th>\n",
       "      <th>Team2Seed</th>\n",
       "      <th>SeedDiff</th>\n",
       "      <th>Team1Loc</th>\n",
       "      <th>Team2Loc</th>\n",
       "      <th>ScoreDiff1</th>\n",
       "      <th>Team1Score_avg</th>\n",
       "      <th>Team1ScoreRatio_avg</th>\n",
       "      <th>ScoreDiff2</th>\n",
       "      <th>Team2Score_avg</th>\n",
       "      <th>Team2ScoreRatio_avg</th>\n",
       "      <th>Lsea_W</th>\n",
       "      <th>Lsea_X</th>\n",
       "      <th>Lsea_Y</th>\n",
       "      <th>Lsea_Z</th>\n",
       "      <th>Wsea_W</th>\n",
       "      <th>Wsea_X</th>\n",
       "      <th>Wsea_Y</th>\n",
       "      <th>Wsea_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.151515</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>0.516269</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>0.476035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.787879</td>\n",
       "      <td>71.030303</td>\n",
       "      <td>0.515335</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.497694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.823529</td>\n",
       "      <td>76.264706</td>\n",
       "      <td>0.538339</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>65.909091</td>\n",
       "      <td>0.476381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.354839</td>\n",
       "      <td>79.290323</td>\n",
       "      <td>0.490979</td>\n",
       "      <td>1.913043</td>\n",
       "      <td>80.913043</td>\n",
       "      <td>0.493927</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.393939</td>\n",
       "      <td>79.575758</td>\n",
       "      <td>0.517562</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>83.125000</td>\n",
       "      <td>0.509532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1Seed  Team2Seed  SeedDiff Team1Loc Team2Loc  ScoreDiff1  \\\n",
       "0       18.0       18.0       0.0        2        0    4.151515   \n",
       "1       18.0       18.0       0.0        0        2    4.787879   \n",
       "2        2.0        9.0      -7.0        1        1   10.823529   \n",
       "3       18.0       18.0       0.0        2        0   -2.354839   \n",
       "4        8.0       18.0     -10.0        2        0    5.393939   \n",
       "\n",
       "   Team1Score_avg  Team1ScoreRatio_avg  ScoreDiff2  Team2Score_avg  \\\n",
       "0       68.666667             0.516269    7.100000       68.500000   \n",
       "1       71.030303             0.515335    0.720000       73.000000   \n",
       "2       76.264706             0.538339    6.272727       65.909091   \n",
       "3       79.290323             0.490979    1.913043       80.913043   \n",
       "4       79.575758             0.517562   -3.500000       83.125000   \n",
       "\n",
       "   Team2ScoreRatio_avg  Lsea_W  Lsea_X  Lsea_Y  Lsea_Z  Wsea_W  Wsea_X  \\\n",
       "0             0.476035       0       0       0       0       0       0   \n",
       "1             0.497694       0       0       0       0       0       0   \n",
       "2             0.476381       0       0       1       0       0       1   \n",
       "3             0.493927       0       0       0       0       0       0   \n",
       "4             0.509532       0       0       0       0       0       0   \n",
       "\n",
       "   Wsea_Y  Wsea_Z  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression & Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Find_features=RFECV(lr,step=1,cv =5,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=5,\n",
       "   estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring='neg_log_loss', step=1, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Find_features.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=[]\n",
    "for i in range(len(Find_features.support_)):\n",
    "    if Find_features.support_[i] == True:\n",
    "        key.append(X_train.keys()[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = Find_features.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_=logloss(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730775613967\n"
     ]
    }
   ],
   "source": [
    "radm = RandomForestClassifier(n_estimators=1000,\n",
    "                                  max_depth=None,\n",
    "                                  min_samples_split=10,\n",
    "                                  class_weight=\"balanced\",\n",
    "                                  random_state=2).fit(X_train, y_train)\n",
    "y_val_1 = radm.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755504933372\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_val_2 = log_reg.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42151467504\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "gnb = GaussianNB().fit(X_train,y_train)\n",
    "y_val_3 = gnb.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837050069743\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "kNN = KNeighborsClassifier(n_neighbors=25).fit(X_train, y_train)\n",
    "y_val_4 = kNN.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756483374805\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "svm = SVC(C=1,kernel='rbf',probability = True).fit(X_train,y_train)\n",
    "\n",
    "y_val_5 = svm.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684435890754\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "ada = AdaBoostClassifier(n_estimators=400, learning_rate=0.1).fit(X_train,y_train)\n",
    "y_val_6 = ada.predict_proba(X_test)\n",
    "print(logloss(y_test,y_val_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
